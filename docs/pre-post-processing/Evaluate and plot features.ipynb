{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook to explore and evalute the extracted features, such as volume, surface or roughness \n",
    "Written by Dominik Waibel & Niklas Kiermeyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import copy\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the respective .csv files\n",
    "data_mask = pd.read_csv(\"./features/mask_features.csv\")\n",
    "data_obj = pd.read_csv( \"./features/SHAPR_features.csv\")\n",
    "data_ellipse = pd.read_csv(\"./features//Ellipse_fit_features.csv\")\n",
    "data_cylinder = pd.read_csv( \"./features/Cylinder_fit.csv\")\n",
    "data_gt = pd.read_csv( \"./features/groundtruth_features.csv\")\n",
    "\n",
    "print(data_mask.shape)\n",
    "print(data_obj.shape)\n",
    "print(data_ellipse.shape)\n",
    "print(data_cylinder.shape)\n",
    "print(data_gt.shape)\n",
    "\n",
    "data_mask = data_mask[data_mask[\"filename_msk\"].isin(data_ellipse[\"filename\"].values)]\n",
    "data_cylinder = data_cylinder[data_cylinder[\"filename\"].isin(data_ellipse[\"filename\"].values)]\n",
    "data_gt = data_gt[data_gt[\"filename\"].isin(data_ellipse[\"filename\"].values)]\n",
    "\n",
    "data_mask = data_mask[data_mask[\"filename_msk\"].isin(data_cylinder[\"filename\"].values)]\n",
    "data_ellipse = data_ellipse[data_ellipse[\"filename\"].isin(data_cylinder[\"filename\"].values)]\n",
    "data_obj = data_obj[data_obj[\"filename\"].isin(data_cylinder[\"filename\"].values)]\n",
    "data_gt = data_gt[data_gt[\"filename\"].isin(data_cylinder[\"filename\"].values)]\n",
    "\n",
    "data_mask = data_mask[data_mask[\"filename_msk\"].isin(data_obj[\"filename\"].values)]\n",
    "data_ellipse = data_ellipse[data_ellipse[\"filename\"].isin(data_obj[\"filename\"].values)]\n",
    "data_cylinder = data_cylinder[data_cylinder[\"filename\"].isin(data_obj[\"filename\"].values)]\n",
    "data_gt = data_gt[data_gt[\"filename\"].isin(data_obj[\"filename\"].values)]\n",
    "\n",
    "data_mask = data_mask[data_mask[\"filename_msk\"].isin(data_gt[\"filename\"].values)]\n",
    "data_ellipse = data_ellipse[data_ellipse[\"filename\"].isin(data_gt[\"filename\"].values)]\n",
    "data_cylinder = data_cylinder[data_cylinder[\"filename\"].isin(data_gt[\"filename\"].values)]\n",
    "data_obj = data_obj[data_obj[\"filename\"].isin(data_gt[\"filename\"].values)]\n",
    "\n",
    "print(data_mask.shape)\n",
    "print(data_obj.shape)\n",
    "print(data_ellipse.shape)\n",
    "print(data_cylinder.shape)\n",
    "print(data_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = data_obj[\"filename\"].values\n",
    "AE_vol = []; ellipse_vol = []; cylinder_vol = []; gt_vol = []; mask_area = []; fname = []\n",
    "\n",
    "for filename in filenames: \n",
    "    AE_vol.append(data_obj[data_obj[\"filename\"]==filename][\"volume\"].values[0])\n",
    "    ellipse_vol.append(data_ellipse[data_ellipse[\"filename\"]==filename][\"volume\"].values[0])\n",
    "    cylinder_vol.append(data_cylinder[data_cylinder[\"filename\"]==filename][\"volume\"].values[0])\n",
    "    gt_vol.append(data_gt[data_gt[\"filename\"]==filename][\"volume\"].values[0])\n",
    "    mask_area.append(data_mask[data_mask[\"filename_msk\"]==filename][\"boundary_msk\"].values[0])\n",
    "    fname.append(filename)\n",
    "AE_vol_error = [np.abs((AE_vol[i]-gt_vol[i])/gt_vol[i]) for i in range(len(gt_vol))]\n",
    "ellipse_vol_error = [np.abs((ellipse_vol[i]-gt_vol[i])/gt_vol[i]) for i in range(len(ellipse_vol))]\n",
    "cylinder_vol_error = [np.abs((cylinder_vol[i]-gt_vol[i])/gt_vol[i]) for i in range(len(cylinder_vol))]\n",
    "print(len(AE_vol_error))\n",
    "print(len(ellipse_vol_error))\n",
    "print(len(cylinder_vol_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(AE_vol_error)*100, np.std(AE_vol_error)*100)\n",
    "print(np.mean(cylinder_vol_error)*100,np.std(cylinder_vol_error)*100)\n",
    "print(np.mean(ellipse_vol_error)*100,np.std(ellipse_vol_error)*100)\n",
    "print(\"median\")\n",
    "print(np.median(AE_vol_error)*100)\n",
    "print(np.median(cylinder_vol_error)*100)\n",
    "print(np.median(ellipse_vol_error)*100)\n",
    "from scipy.stats import wilcoxon\n",
    "print(wilcoxon(AE_vol_error,cylinder_vol_error))\n",
    "print(wilcoxon(AE_vol_error,ellipse_vol_error))\n",
    "plt.figure(figsize =(8,6))\n",
    "ax = sns.violinplot(data = [AE_vol_error, cylinder_vol_error, ellipse_vol_error], \n",
    "            showfliers=False,color='lightgray', boxprops={'facecolor':'None'},orient = \"h\")\n",
    "ax = sns.swarmplot(data = [AE_vol_error, cylinder_vol_error, ellipse_vol_error],color=\".25\", size = 1.5, orient = \"h\")\n",
    "#plt.title('Volume error', size = 15)\n",
    "plt.xlabel('Wrongly labeled voxels', size = 15)\n",
    "plt.yticks([0, 1, 2], [\"SHAPR\",\"Cylinder\",\n",
    "                       \"Ellipse\"], size = 15)\n",
    "\n",
    "plt.xlim(-0.15,1.3)\n",
    "\n",
    "#plt.yscale(\"log\")\n",
    "plt.grid(b=None)\n",
    "\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.tight_layout()\n",
    "plt.grid(b=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,fn in enumerate(fname): \n",
    "    if AE_vol_error[i] > 1.5:\n",
    "        print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,6))\n",
    "plt.scatter(mask_area, AE_vol, s = 4, c = \"r\", alpha = 0.5)\n",
    "plt.scatter(mask_area, ellipse_vol, s = 4, c = \"b\", alpha = 0.5)\n",
    "plt.scatter(mask_area, cylinder_vol, s =4, c = \"g\", alpha = 0.5)\n",
    "plt.scatter(mask_area, gt_vol, s = 4, c = \"black\", alpha = 0.5)\n",
    "plt.tight_layout()\n",
    "plt.grid(b=None)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_csv = pd.read_csv(\"./SHAPR_dataset/mask_positions.csv\")\n",
    "z_position = []\n",
    "for fn in fname:\n",
    "    z_position.append(position_csv[position_csv[\"filename\"]==fn][\"organoid_z_center_of_mass\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_position_shifted = [z-22 for z in z_position]\n",
    "z_position_shifted = np.abs(z_position_shifted)\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.scatter(AE_vol_error, z_position_shifted, s = 4, c = \"black\", alpha = 0.5)\n",
    "plt.tight_layout()\n",
    "plt.grid(b=None)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.grid(b=None)\n",
    "plt.xlim(-0.05,1.3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
